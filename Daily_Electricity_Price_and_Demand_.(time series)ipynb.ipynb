{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Daily Electricity Price and Demand .ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip "
      ],
      "metadata": {
        "id": "xI5mOVOv-IHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YZyXfq6zCzhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "You work for an energy company in Australia. Your company builds solar panel arrays and then sells the energy they produce to industrial customers. The company wants to expand to the city of Melbourne in the state of Victoria. Prices and demand for electricity change every day. Customers pay for the energy received using a formula based on the local energy market's daily price. Your company's pricing committee wants your team to estimate energy prices for the next 12-18 months to use those prices as the basis for contract negotiations. In addition, the VP of strategy is researching investing in storage capacity (i.e., batteries) as a new source of revenue. The plan is to store some of the energy produced by the solar panels when pricing conditions are unfavorable and sell it by the next day on the open market if the prices are higher.\n"
      ],
      "metadata": {
        "id": "YEyOTnxqC0VH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  date\n",
        "    datetime, the date of the recording\n",
        "    Sort datetime, the date of the recording\n",
        "   demand\n",
        "    float, a total daily electricity demand in MWh\n",
        "   RRP\n",
        "    float, a recommended retail price in AUD$ / MWh\n",
        "   demand_pos_RRP\n",
        "    float, a total daily demand at positive RRP in MWh\n",
        "  RRP_positive\n",
        "    float, an averaged positive RRP, weighted by the corresponding       intraday  demand in AUD$ / MWh\n",
        "   demand_neg_RRP\n",
        "    float, an total daily demand at negative RRP in MWh\n",
        "   RRP_negative\n",
        "    float, an average negative RRP, weighted by the corresponding intraday demand in AUD$ / MWh*\n",
        "   frac_at_neg_RRP\n",
        "    float, an average negative RRP, weighted by the corresponding intraday demand in AUD$ / MWh\n",
        "   min_temperature\n",
        "    float, minimum temperature during the day in Celsius\n",
        "   max_temperature\n",
        "    float, maximum temperature during the day in Celsius"
      ],
      "metadata": {
        "id": "hDBrYS_0EmL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NZHsdBEsARZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J6cF0s_iAU4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "df=pd.read_csv('/content/complete_dataset.csv')"
      ],
      "metadata": {
        "id": "pw1J43Pvwfgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "in5VCrMQ5nPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)\n"
      ],
      "metadata": {
        "id": "ykOVBl8o2Yiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(df, html = {'style' : {'full_width':True}})\n",
        "profile.to_file(output_file=\"report.html\")\n",
        "profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "LA6xnM-Zwmt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your challenge\n",
        "Create a report that covers the following:\n",
        "\n",
        "How do energy prices change throughout the year? Are there any patterns by season or month of the year?\n",
        "Build a forecast of daily energy prices the company can use as the basis of its financial planning.\n",
        "Provide guidance on how much revenue the energy storage venture could generate per year using retail prices and a 70MWh storage system.\n"
      ],
      "metadata": {
        "id": "YQviRIM6AXeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demand_df=df[['date','demand']].rename(columns={'date':'ds','demand':'y'})\n",
        "demand_df['ds']=pd.to_datetime(demand_df['ds'])\n",
        "demand_df.head()"
      ],
      "metadata": {
        "id": "OFdDYpRvAcPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zTJBBcZuMFAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.title(\"All Data\")\n",
        "plt.plot(demand_df['ds'].dt.to_pydatetime(),demand_df['y'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HUsoL4RuMU_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the insights shows some yearly seasonality: the energy demand encreases evry year until june, then it decrease for  the rest of the year"
      ],
      "metadata": {
        "id": "wjJZgWp0O0gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6YLcZHUsN_TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title('first 100 days')\n",
        "plt.plot(demand_df['ds'].dt.to_pydatetime()[:100], demand_df['y'][:100])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m0pQ4gZSN_th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qJc2AnVgOyQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can notice that the energy demand is not consistent day to day \n"
      ],
      "metadata": {
        "id": "puuxZz_BPmQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=8\n",
        "df_train , df_valid= demand_df[:int(len(demand_df)*0.8)] ,demand_df[int(len(demand_df)*0.8):]\n",
        "df_valid, df_test = df_valid[:len(df_valid)//2], df_valid[len(df_valid)//2:]\n",
        "def train_valid_plot():\n",
        "    \"\"\"Visualizing the training + validation sets\"\"\"\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(df_train['ds'].dt.to_pydatetime(), df_train[\"y\"], color='#1f76b4', label='Training Set')\n",
        "    ax.plot(df_valid['ds'].dt.to_pydatetime(), df_valid[\"y\"], color='#fc7d0b', label='Validation Set')\n",
        "    ax.plot(df_test['ds'].dt.to_pydatetime(), df_valid[\"y\"], color='#CDC7E5', label='Test Set')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "    \n",
        "train_valid_plot()"
      ],
      "metadata": {
        "id": "oLAV__kwQJaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a Model\n",
        "We use 'D' to set the frequency of predictions as daily, and we use plot-all to visualize model performance live during training. The only other alteration we make is to specify Australian holidays.\n"
      ],
      "metadata": {
        "id": "JAtpbBMuzPjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NeuralProphet\n",
        "!pip install neuralprophet[live] --quiet\n",
        "\n",
        "\n",
        "\n",
        "set_random_seed(0)"
      ],
      "metadata": {
        "id": "dxFRU17gzMAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralprophet import NeuralProphet\n",
        "from neuralprophet import set_random_seed"
      ],
      "metadata": {
        "id": "Cz-V7kTX1rRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = NeuralProphet()\n",
        "\n",
        "m.add_country_holidays(country_name='Australia')\n",
        "metrics = m.fit(df=df_train, validation_df=df_valid, freq=\"D\", progress=\"plot-all\")\n",
        "metrics[-1:]"
      ],
      "metadata": {
        "id": "AZLCn57N0XAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the graph above that the model is being overfit to the data. The model is fitting as low as it can on the training data, but we want the model to fit well on unseen data (ie. validation set). \n",
        "\n",
        "Looking at the metric plots above, we can see that the optimal parameters are reached around 25â€“30 epochs and then the model starts to overfit. We can combat this by specifying a number of epochs. A complete list of tuneable model parameters can be found here."
      ],
      "metadata": {
        "id": "Z-vTIeHl3fYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = NeuralProphet(epochs=30)\n",
        "m.add_country_holidays(country_name='Australia')\n",
        "metrics2 = m.fit(df=df_train, validation_df=df_valid, freq=\"D\" ,progress=\"plot-all\")\n",
        "metrics2[-1:]"
      ],
      "metadata": {
        "id": "LR7N518X3gxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating a Model\n"
      ],
      "metadata": {
        "id": "iFyKzPwJ4rxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future = m.make_future_dataframe(df=df_train, periods=len(df_valid), n_historic_predictions=True)\n",
        "forecast = m.predict(df=future)\n",
        "fig_forecast = m.plot(forecast)"
      ],
      "metadata": {
        "id": "iw8ehJTE4zYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Train RMSE: {:.2f} --- Validation RMSE: {:.2f}\".format(metrics2[-1:].RMSE.values[0], metrics2[-1:].RMSE_val.values[0]))\n",
        "ax.plot(df_valid['ds'].dt.to_pydatetime(), df_valid[\"y\"],'.k', label='True Value')\n",
        "ax.plot(forecast[-len(df_valid):]['ds'].dt.to_pydatetime(), forecast[-len(df_valid):][\"yhat1\"], label='Predicted Value')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZqibN8fl5u6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the third plot, we are looking at the yearly seasonality. We can see that energy demand is at its lowest in April and October, and energy demand is at its highest in July. "
      ],
      "metadata": {
        "id": "UhBEKt7z7QS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_param = m.plot_parameters()"
      ],
      "metadata": {
        "id": "cFrCHKU47R9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding AR-Net (AutoRegression)\n",
        "One of the new additions in Prophet is AR-Net (Auto-Regressive Neural Network). This allows NeuralProphet to use observations from previous time steps when making a prediction. In our case, this means that the model can use the previous day's energy demands to make its predictions."
      ],
      "metadata": {
        "id": "16gIUijf8j95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = NeuralProphet(n_forecasts=1, n_lags=3, epochs=30, changepoints_range=0.95)\n",
        "m.add_country_holidays(country_name='Australia')\n",
        "metrics3 = m.fit(df=df_train, validation_df=df_valid, freq=\"D\")\n",
        "metrics3[-1:]"
      ],
      "metadata": {
        "id": "Hecxhn8N7SV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "NduomWax_vpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the metrics above that the validation RMSE decreased again. This is another significant gain in model performance we got by simply tuning two parameters.\n",
        "\n",
        "If we use the same code that we did previously, only one prediction is made. It is unclear from the docs how to make \"running\" predictions when AR-Net is enabled, and therefore we can use the following code to make this possible. If anyone knows a built-in way to do this please let me know!\n"
      ],
      "metadata": {
        "id": "RQriQ3b69U1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " valid_preds = [] #list to store predictions\n",
        "lags = 3\n",
        "\n",
        "for d in df_valid['ds'].values:\n",
        "    # getting necessary df rows\n",
        "    date_index = demand_df.index[demand_df['ds'] == d][0]\n",
        "    future = demand_df.iloc[date_index-lags:date_index]\n",
        "    \n",
        "    # adding new row\n",
        "    entry = pd.DataFrame({\n",
        "        'ds': [d],\n",
        "        'y' : [np.nan]\n",
        "    })\n",
        "    future = pd.concat([future, entry], ignore_index = True, axis = 0)\n",
        "    \n",
        "    # making prediction\n",
        "    forecast = m.predict(df=future)\n",
        "    valid_preds.append(forecast.loc[lags]['yhat1'])"
      ],
      "metadata": {
        "id": "_tiSZBlV9WRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then use the following code block to plot our predictions. We can see from the plot that the model is starting to pick up on outlying points.\n",
        "\n"
      ],
      "metadata": {
        "id": "U_2rxQtWAGDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DF for predictions\n",
        "df_valid_copy = df_valid.copy()\n",
        "df_valid_copy['yhat1'] = valid_preds\n",
        "df_valid_copy.head()\n",
        "\n",
        "# Plotting Predictions\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Train RMSE: {:.2f} --- Validation RMSE: {:.2f}\".format(metrics3[-1:].RMSE.values[0], metrics3[-1:].RMSE_val.values[0]))\n",
        "ax.plot(df_valid_copy['ds'].dt.to_pydatetime(), df_valid_copy[\"y\"],'.k', label='True Value')\n",
        "ax.plot(df_valid_copy['ds'].dt.to_pydatetime(), df_valid_copy[\"yhat1\"], label='Predicted Value')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yZWXh_cJAKNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n"
      ],
      "metadata": {
        "id": "FH8Zyb7oCqDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # Store the RMSEs for each params here\n",
        "# Parameter Options\n",
        "param_grid = {  \n",
        "    'num_hidden_layers': [1,2],\n",
        "    'changepoints_range': [0.95, 0.975, 0.99, 0.995, 0.999],\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "# Use cross validation to evaluate all parameters\n",
        "for params in all_params:\n",
        "    m = NeuralProphet(**params, n_forecasts=1, newer_samples_weight=4, n_lags=3, learning_rate=0.02, epochs=50, batch_size=32)\n",
        "    m.add_country_holidays(country_name='Australia')\n",
        "    metrics4 = m.fit(df=df_train, validation_df=df_valid, freq=\"D\")\n",
        "    results.append(dict({\"RMSE_val\": metrics4['RMSE_val'].min(), \"RMSE_train\": metrics4['RMSE'][metrics4['RMSE_val'].idxmin()], \"score_epoch_number\": metrics4['RMSE_val'].idxmin()}, **params))"
      ],
      "metadata": {
        "id": "YDZz50OMADhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best parameters\n",
        "results_df = pd.DataFrame.from_dict(results, orient='columns')\n",
        "results_df = results_df.sort_values('RMSE_val')\n",
        "results_df.head(10)"
      ],
      "metadata": {
        "id": "4TBJG_WyEjwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = NeuralProphet(newer_samples_weight=5, n_forecasts=1, n_lags=3, learning_rate=0.02, epochs=25, batch_size=32, num_hidden_layers=1, changepoints_range=0.995)\n",
        "m.add_country_holidays(country_name='Australia')\n",
        "metrics5 = m.fit(df=df_train, validation_df=df_valid, freq=\"D\", progress=\"plot-all\")\n",
        "metrics5[-1:]\n"
      ],
      "metadata": {
        "id": "8YIBzpEbFMNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_preds = [] #list to store predictions\n",
        "lags = 3\n",
        "\n",
        "for d in df_valid['ds'].values:\n",
        "    # getting necessary df rows\n",
        "    date_index = demand_df.index[demand_df['ds'] == d][0]\n",
        "    future = demand_df.iloc[date_index-lags:date_index]\n",
        "    \n",
        "    # adding new row\n",
        "    entry = pd.DataFrame({\n",
        "        'ds': [d],\n",
        "        'y' : [np.nan]\n",
        "    })\n",
        "    future = pd.concat([future, entry], ignore_index = True, axis = 0)\n",
        "    \n",
        "    # making prediction\n",
        "    forecast = m.predict(df=future)\n",
        "    valid_preds.append(forecast.loc[lags]['yhat1'])"
      ],
      "metadata": {
        "id": "lcWCXBySGNtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7YrCNvI6GU1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DF for predictions\n",
        "df_valid_copy = df_valid.copy()\n",
        "df_valid_copy['yhat1'] = valid_preds\n",
        "df_valid_copy.head()\n",
        "\n",
        "# Plotting Predictions\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Train RMSE: {:.2f} --- Validation RMSE: {:.2f}\".format(metrics5[-1:].RMSE.values[0], metrics5[-1:].RMSE_val.values[0]))\n",
        "ax.plot(df_valid_copy['ds'].dt.to_pydatetime(), df_valid_copy[\"y\"],'.k', label='True Value')\n",
        "ax.plot(df_valid_copy['ds'].dt.to_pydatetime(), df_valid_copy[\"yhat1\"], label='Predicted Value')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bW6meDIEGVFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}